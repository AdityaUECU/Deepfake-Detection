# -*- coding: utf-8 -*-
"""Xception-LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tOsvAmXrKaKK3Rsw9rBZSdiupuvV1vOJ
"""

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import Xception
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import TimeDistributed, LSTM, Dense, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from tensorflow.keras.regularizers import l2

input_shape = (10, 224, 224, 3)  # 10 frames per video, 224x224 size, 3 color channels
num_classes = 2

# Data Preprocessing
def load_videos_from_folder(folder, label, max_videos=None):
    videos = []
    labels = []
    for i, filename in enumerate(os.listdir(folder)):
        if max_videos and i >= max_videos:
            break
        video_path = os.path.join(folder, filename)
        cap = cv2.VideoCapture(video_path)
        frames = []
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            frame = cv2.resize(frame, (224, 224))
            frames.append(frame)
            if len(frames) == input_shape[0]:
                break
        cap.release()
        if len(frames) == input_shape[0]:
            videos.append(np.array(frames))
            labels.append(label)
    return np.array(videos), np.array(labels)

# Load Dataset
real_videos, real_labels = load_videos_from_folder('/content/drive/MyDrive/Real-videos', label=0, max_videos=150)
fake_videos, fake_labels = load_videos_from_folder('/content/drive/MyDrive/Deepfake-videos', label=1, max_videos=150)

# Combine and Shuffle Dataset
X = np.concatenate((real_videos, fake_videos), axis=0)
y = np.concatenate((real_labels, fake_labels), axis=0)
y = to_categorical(y, num_classes)

# Normalize the data
X = X / 255.0

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# CNN Model
cnn_base = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
cnn_out = Flatten()(cnn_base.output)
cnn_model = Model(inputs=cnn_base.input, outputs=cnn_out)

# Freeze CNN base
for layer in cnn_base.layers:
    layer.trainable = False

# LSTM Model
model = Sequential()
model.add(TimeDistributed(cnn_model, input_shape=input_shape))
model.add(LSTM(64, return_sequences=False, kernel_regularizer=l2(0.01)))
model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))
model.add(Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.01)))

model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Summary
model.summary()

# Training
history = model.fit(X_train, y_train, epochs=10, batch_size=12, validation_split=0.2)

# Evaluation
loss, accuracy = model.evaluate(X_test, y_test, batch_size=10)
print(f'Test Loss: {loss}')
print(f'Test Accuracy: {accuracy}')

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], color='red', label='train')
plt.plot(history.history['val_accuracy'], color='blue', label='validation')
plt.legend()
plt.show()

import matplotlib.pyplot as plt

plt.plot(history.history['loss'], color='red', label='train')
plt.plot(history.history['val_loss'], color='blue', label='validation')
plt.legend()
plt.show()

# Function to predict an unseen video and get the probability
def predict_video(video_path, model, input_shape):
    cap = cv2.VideoCapture(video_path)
    frames = []
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.resize(frame, (224, 224))
        frames.append(frame)
        if len(frames) == input_shape[0]:
            break
    cap.release()

    if len(frames) < input_shape[0]:
        raise ValueError("Video is shorter than the expected number of frames.")

    frames = np.array(frames)
    frames = frames / 255.0  # Normalize to range [0, 1]
    frames = np.expand_dims(frames, axis=0)  # Add batch dimension

    prediction = model.predict(frames)
    predicted_class = np.argmax(prediction)
    probability = prediction[0][predicted_class]

    return predicted_class, probability

# Predict on an unseen video
video_path = '/content/id0_id2_0004.mp4'
predicted_class, probability = predict_video(video_path, model, input_shape)

if predicted_class == 0:
    print(f"The video is real with a probability of {probability:.2f}.")
else:
    print(f"The video is fake with a probability of {probability:.2f}.")

