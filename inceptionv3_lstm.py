# -*- coding: utf-8 -*-
"""INCEPTIONV3-LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sLWzZp9v9TrdFKMgQWpuAhg24UOSrfkr
"""

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import TimeDistributed, LSTM, Dense, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Parameters
input_shape = (10, 224, 224, 3)  # 10 frames per video, 224x224 size, 3 color channels
num_classes = 2  # Real or Fake

# Data Preprocessing
def load_videos_from_folder(folder, label, max_videos=None):
    videos = []
    labels = []
    for i, filename in enumerate(os.listdir(folder)):
        if max_videos and i >= max_videos:
            break
        video_path = os.path.join(folder, filename)
        cap = cv2.VideoCapture(video_path)
        frames = []
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            frame = cv2.resize(frame, (224, 224))
            frames.append(frame)
            if len(frames) == input_shape[0]:
                break
        cap.release()
        if len(frames) == input_shape[0]:
            videos.append(np.array(frames))
            labels.append(label)
    return np.array(videos), np.array(labels)

# Load Dataset
real_videos, real_labels = load_videos_from_folder('/content/drive/MyDrive/Real-videos', label=0, max_videos=150)
fake_videos, fake_labels = load_videos_from_folder('/content/drive/MyDrive/Deepfake-videos', label=1, max_videos=150)

# Combine and Shuffle Dataset
X = np.concatenate((real_videos, fake_videos), axis=0)
y = np.concatenate((real_labels, fake_labels), axis=0)
y = to_categorical(y, num_classes)

# Normalize the data
X = X / 255.0

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# CNN Model
cnn_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
cnn_out = Flatten()(cnn_base.output)
cnn_model = Model(inputs=cnn_base.input, outputs=cnn_out)

# Freeze CNN base
for layer in cnn_base.layers:
    layer.trainable = False

# LSTM Model
model = Sequential()
model.add(TimeDistributed(cnn_model, input_shape=input_shape))
model.add(LSTM(64, return_sequences=False))
model.add(Dense(128, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Summary
model.summary()

history = model.fit(X_train, y_train, epochs=10, batch_size=12, validation_split=0.2)

# Evaluation
loss, accuracy = model.evaluate(X_test, y_test, batch_size=12)
print(f'Test Loss: {loss}')
print(f'Test Accuracy: {accuracy}')

def predict_and_show_video(video_path, model, input_shape):
    cap = cv2.VideoCapture(video_path)
    frames = []

    fig, axes = plt.subplots(1, input_shape[0], figsize=(20, 5))
    fig.suptitle("Video Frames", fontsize=20)

    # Read video and process frames
    for i in range(input_shape[0]):
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.resize(frame, (224, 224))
        frames.append(frame)
        # Display the frame
        axes[i].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        axes[i].axis('off')

    cap.release()

    # Ensure there are enough frames
    if len(frames) < input_shape[0]:
        raise ValueError(f"Video must have at least {input_shape[0]} frames.")

    # Convert frames to a numpy array and normalize
    frames = np.array(frames)
    frames = frames / 255.0  # Normalize to range [0, 1]
    frames = np.expand_dims(frames, axis=0)  # Add batch dimension

    # Make prediction
    prediction = model.predict(frames)
    predicted_class = np.argmax(prediction)
    probability = prediction[0][predicted_class]

    plt.show()

    return predicted_class, probability

video_path = '/content/id0_id4_0004.mp4'
predicted_class, probability = predict_and_show_video(video_path, model, input_shape)

if predicted_class == 0:
    print(f"The video is real with a probability of {probability:.2f}.")
else:
    print(f"The video is fake with a probability of {probability:.2f}.")

video_path = '/content/id0_0004.mp4'
predicted_class, probability = predict_and_show_video(video_path, model, input_shape)

if predicted_class == 0:
    print(f"The video is real with a probability of {probability:.2f}.")
else:
    print(f"The video is fake with a probability of {probability:.2f}.")